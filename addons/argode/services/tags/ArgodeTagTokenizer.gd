# ArgodeTagTokenizer
# ãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒˆãƒ¼ã‚¯ãƒ³ï¼ˆå˜èªã‚„è¨˜å·ã®æœ€å°å˜ä½ï¼‰ã«åˆ†è§£ã™ã‚‹ã€‚

extends RefCounted
class_name ArgodeTagTokenizer

## ãƒˆãƒ¼ã‚¯ãƒ³ã®ç¨®é¡ã‚’è¡¨ã™enum
enum TokenType {
	TEXT,     # é€šå¸¸ã®ãƒ†ã‚­ã‚¹ãƒˆ
	TAG,      # ã‚¿ã‚° {w=1.0} ãªã©
	VARIABLE, # å¤‰æ•° [player.name] ãªã©  
	RUBY      # ãƒ«ãƒ“ ã€å¤ä»Šæ±è¥¿ï½œã“ã“ã‚“ã¨ã†ã–ã„ã€‘ãªã©
}

## ãƒˆãƒ¼ã‚¯ãƒ³ãƒ‡ãƒ¼ã‚¿æ§‹é€ 
class TokenData extends RefCounted:
	var type: TokenType
	var content: String        # å…ƒã®ãƒ†ã‚­ã‚¹ãƒˆå†…å®¹
	var start_position: int    # ãƒ†ã‚­ã‚¹ãƒˆå†…ã§ã®é–‹å§‹ä½ç½®
	var end_position: int      # ãƒ†ã‚­ã‚¹ãƒˆå†…ã§ã®çµ‚äº†ä½ç½®
	var display_text: String   # è¡¨ç¤ºç”¨ãƒ†ã‚­ã‚¹ãƒˆï¼ˆåŠ å·¥å¾Œï¼‰
	var command_data: Dictionary = {}  # ã‚³ãƒãƒ³ãƒ‰å®Ÿè¡Œç”¨ãƒ‡ãƒ¼ã‚¿
	
	func _init(p_type: TokenType, p_content: String, p_start: int, p_end: int):
		type = p_type
		content = p_content
		start_position = p_start
		end_position = p_end
		display_text = p_content  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯å…ƒã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„

## ãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒˆãƒ¼ã‚¯ãƒ³ã«åˆ†è§£
func tokenize(text: String) -> Array[TokenData]:
	var tokens: Array[TokenData] = []
	var current_pos = 0
	
	while current_pos < text.length():
		var next_token = _find_next_token(text, current_pos)
		if next_token:
			tokens.append(next_token)
			current_pos = next_token.end_position
		else:
			# æ®‹ã‚Šã®ãƒ†ã‚­ã‚¹ãƒˆã‚’é€šå¸¸ãƒ†ã‚­ã‚¹ãƒˆã¨ã—ã¦å‡¦ç†
			var remaining_text = text.substr(current_pos)
			if not remaining_text.is_empty():
				var text_token = TokenData.new(TokenType.TEXT, remaining_text, current_pos, text.length())
				tokens.append(text_token)
			break
	
	return tokens

## TokenTypeã‚’æ–‡å­—åˆ—ã«å¤‰æ›ï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰
func _token_type_to_string(type: TokenType) -> String:
	match type:
		TokenType.TEXT: return "TEXT"
		TokenType.TAG: return "TAG"
		TokenType.VARIABLE: return "VARIABLE"
		TokenType.RUBY: return "RUBY"
		_: return "UNKNOWN"

## æŒ‡å®šä½ç½®ã‹ã‚‰æ¬¡ã®ãƒˆãƒ¼ã‚¯ãƒ³ã‚’æ¤œç´¢
func _find_next_token(text: String, start_pos: int) -> TokenData:
	var remaining_text = text.substr(start_pos)
	
	ArgodeSystem.log("ğŸ” Finding token from pos %d: '%s'" % [start_pos, remaining_text.substr(0, 30) + ("..." if remaining_text.length() > 30 else "")])
	
	# æœ€åˆã«ç‰¹æ®Šãƒ‘ã‚¿ãƒ¼ãƒ³ã®ä½ç½®ã‚’èª¿ã¹ã‚‹
	var earliest_pattern_pos = -1
	var earliest_pattern_type = ""
	
	# ã‚¿ã‚°ã®æ¤œç´¢ {xxx}
	var tag_match = _find_tag_pattern(remaining_text)
	if tag_match.has("found"):
		if earliest_pattern_pos == -1 or tag_match.start < earliest_pattern_pos:
			earliest_pattern_pos = tag_match.start
			earliest_pattern_type = "tag"
	
	# å¤‰æ•°ã®æ¤œç´¢ [xxx]
	var var_match = _find_variable_pattern(remaining_text)
	if var_match.has("found"):
		if earliest_pattern_pos == -1 or var_match.start < earliest_pattern_pos:
			earliest_pattern_pos = var_match.start
			earliest_pattern_type = "variable"
	
	# ãƒ«ãƒ“ã®æ¤œç´¢ ã€xxxï½œyyyã€‘
	var ruby_match = _find_ruby_pattern(remaining_text)
	if ruby_match.has("found"):
		if earliest_pattern_pos == -1 or ruby_match.start < earliest_pattern_pos:
			earliest_pattern_pos = ruby_match.start
			earliest_pattern_type = "ruby"
	
	# ç‰¹æ®Šãƒ‘ã‚¿ãƒ¼ãƒ³ã®å‰ã«ãƒ†ã‚­ã‚¹ãƒˆãŒã‚ã‚‹å ´åˆã¯ãƒ†ã‚­ã‚¹ãƒˆãƒˆãƒ¼ã‚¯ãƒ³ã‚’å…ˆã«ä½œæˆ
	if earliest_pattern_pos > 0:
		var text_content = remaining_text.substr(0, earliest_pattern_pos)
		return TokenData.new(TokenType.TEXT, text_content, start_pos, start_pos + text_content.length())
	
	# ç‰¹æ®Šãƒ‘ã‚¿ãƒ¼ãƒ³ãŒå…ˆé ­ã«ã‚ã‚‹å ´åˆã¯è©²å½“ã™ã‚‹ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å‡¦ç†
	if earliest_pattern_pos == 0:
		match earliest_pattern_type:
			"tag":
				return _create_tag_token(tag_match, start_pos)
			"variable":
				return _create_variable_token(var_match, start_pos)
			"ruby":
				return _create_ruby_token(ruby_match, start_pos)
	
	# ç‰¹æ®Šãƒ‘ã‚¿ãƒ¼ãƒ³ãŒãªã„å ´åˆã€æ®‹ã‚Šå…¨ã¦ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’ä½œæˆ
	if earliest_pattern_pos == -1:
		return _create_text_token(remaining_text, start_pos)
	
	return null
	
	return null

## ã‚¿ã‚°ãƒ‘ã‚¿ãƒ¼ãƒ³ã®æ¤œç´¢ {xxx}
func _find_tag_pattern(text: String) -> Dictionary:
	var regex = RegEx.new()
	regex.compile(r"\{([^}]+)\}")
	var result = regex.search(text)
	
	if result:
		return {
			"found": true,
			"full_match": result.get_string(0),
			"tag_content": result.get_string(1),
			"start": result.get_start(),
			"end": result.get_end()
		}
	return {}

## å¤‰æ•°ãƒ‘ã‚¿ãƒ¼ãƒ³ã®æ¤œç´¢ [xxx]
func _find_variable_pattern(text: String) -> Dictionary:
	var regex = RegEx.new()
	regex.compile(r"\[([^\]]+)\]")
	var result = regex.search(text)
	
	if result:
		return {
			"found": true,
			"full_match": result.get_string(0),
			"var_content": result.get_string(1),
			"start": result.get_start(),
			"end": result.get_end()
		}
	return {}

## ãƒ«ãƒ“ãƒ‘ã‚¿ãƒ¼ãƒ³ã®æ¤œç´¢ ã€xxxï½œyyyã€‘
func _find_ruby_pattern(text: String) -> Dictionary:
	var regex = RegEx.new()
	regex.compile(r"ã€([^ï½œ]+)ï½œ([^ã€‘]+)ã€‘")
	var result = regex.search(text)
	
	if result:
		return {
			"found": true,
			"full_match": result.get_string(0),
			"base_text": result.get_string(1),   # ãƒ«ãƒ“ãƒ™ãƒ¼ã‚¹ã¨ãªã‚‹æ–‡å­—
			"ruby_text": result.get_string(2),  # ãƒ«ãƒ“ãƒ†ã‚­ã‚¹ãƒˆ
			"start": result.get_start(),
			"end": result.get_end()
		}
	return {}

## ã‚¿ã‚°ãƒˆãƒ¼ã‚¯ãƒ³ã®ä½œæˆ
func _create_tag_token(match_data: Dictionary, offset: int) -> TokenData:
	var start_pos = offset + match_data.start
	var end_pos = offset + match_data.end
	var token = TokenData.new(TokenType.TAG, match_data.full_match, start_pos, end_pos)
	
	# ã‚¿ã‚°å†…å®¹ã‚’è§£æã—ã¦ã‚³ãƒãƒ³ãƒ‰ãƒ‡ãƒ¼ã‚¿ã‚’è¨­å®š
	var tag_content = match_data.tag_content
	token.command_data = _parse_tag_content(tag_content)
	token.display_text = ""  # ã‚¿ã‚°ã¯è¡¨ç¤ºã—ãªã„
	
	return token

## å¤‰æ•°ãƒˆãƒ¼ã‚¯ãƒ³ã®ä½œæˆ
func _create_variable_token(match_data: Dictionary, offset: int) -> TokenData:
	var start_pos = offset + match_data.start
	var end_pos = offset + match_data.end
	var token = TokenData.new(TokenType.VARIABLE, match_data.full_match, start_pos, end_pos)
	
	# å¤‰æ•°åã‚’è¨­å®š
	token.command_data["variable_name"] = match_data.var_content
	token.display_text = "[VAR]"  # ä¸€æ™‚çš„ãªè¡¨ç¤ºãƒ†ã‚­ã‚¹ãƒˆï¼ˆå¾Œã§å¤‰æ•°å€¤ã«ç½®æ›ï¼‰
	
	return token

## ãƒ«ãƒ“ãƒˆãƒ¼ã‚¯ãƒ³ã®ä½œæˆ
func _create_ruby_token(match_data: Dictionary, offset: int) -> TokenData:
	var start_pos = offset + match_data.start
	var end_pos = offset + match_data.end
	var token = TokenData.new(TokenType.RUBY, match_data.full_match, start_pos, end_pos)
	
	# ãƒ«ãƒ“ãƒ‡ãƒ¼ã‚¿ã‚’è¨­å®š
	token.command_data["base_text"] = match_data.base_text
	token.command_data["ruby_text"] = match_data.ruby_text
	token.display_text = match_data.base_text  # è¡¨ç¤ºç”¨ã¯ãƒ™ãƒ¼ã‚¹ãƒ†ã‚­ã‚¹ãƒˆã®ã¿
	
	return token

## é€šå¸¸ãƒ†ã‚­ã‚¹ãƒˆãƒˆãƒ¼ã‚¯ãƒ³ã®ä½œæˆ
func _create_text_token(text: String, offset: int) -> TokenData:
	# æ¬¡ã®ç‰¹æ®Šãƒ‘ã‚¿ãƒ¼ãƒ³ã¾ã§ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—
	var min_pos = text.length()
	
	# å„ãƒ‘ã‚¿ãƒ¼ãƒ³ã®æœ€åˆã®å‡ºç¾ä½ç½®ã‚’èª¿ã¹ã‚‹
	var patterns = [r"\{", r"\[", r"ã€"]
	for pattern in patterns:
		var regex = RegEx.new()
		regex.compile(pattern)
		var result = regex.search(text)
		if result:
			min_pos = min(min_pos, result.get_start())
	
	# min_posãŒ0ã®å ´åˆã€ãƒ†ã‚­ã‚¹ãƒˆã®å…ˆé ­ã«ç‰¹æ®Šãƒ‘ã‚¿ãƒ¼ãƒ³ãŒã‚ã‚‹
	# ã“ã®å ´åˆã¯ç‰¹æ®Šãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å‡¦ç†ã™ã‚‹ãŸã‚ã€nullã‚’è¿”ã™
	if min_pos == 0:
		return null
	
	var content = text.substr(0, min_pos)
	if content.is_empty():
		return null
	
	ArgodeSystem.log("ğŸ“ Creating text token: '%s' (length: %d)" % [content, content.length()])
	return TokenData.new(TokenType.TEXT, content, offset, offset + content.length())

## ã‚¿ã‚°å†…å®¹ã‚’ãƒ‘ãƒ¼ã‚¹ï¼ˆä¾‹: "w=1.0" -> {"command": "w", "value": "1.0"}ï¼‰
func _parse_tag_content(tag_content: String) -> Dictionary:
	var data = {}
	
	ArgodeSystem.log("ğŸ·ï¸ Parsing tag content: '%s'" % tag_content)
	
	if "=" in tag_content:
		var parts = tag_content.split("=", false, 1)
		if parts.size() >= 2:
			data["command"] = parts[0].strip_edges()
			data["value"] = parts[1].strip_edges()
			# WaitCommandã®å ´åˆã€"w"å¼•æ•°ã‚‚è¿½åŠ 
			data[data["command"]] = data["value"]
		else:
			data["command"] = tag_content.strip_edges()
	else:
		data["command"] = tag_content.strip_edges()
	
	ArgodeSystem.log("ğŸ“‹ Parsed tag data: %s" % str(data))
	return data